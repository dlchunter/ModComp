import random
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

# Basic constants
gamma = 0.1
beta = 0.2
alpha = 0.9
l0 = 1
l1 = 5

n = 10
T = 100
# Define rows of probabilities:
state0probs = [1-gamma,0,gamma]
state1probs = [0,1-gamma,gamma]
state2probs = [beta/2, beta/2, 1-beta]

# Make Gamma matrix of probabilities:
Gamma = np.matrix([state0probs, state1probs, state2probs])

C1 = 2
Clist = [C1]
Zlist = []

random.seed(0)

# States are generated by probabilities from Gamma matrix. The states are then appended and returned in the function underneath.
def moveForward(state,iters):
    states = []
    for _ in range(iters):
        if state == 0:
            state = 0 if random.random() < state0probs[0] else 2
        elif state == 1:
            state = 1 if random.random() < state1probs[1] else 2
        else:
            state = 0 if random.random() < state2probs[0] else (1 if random.random() < state2probs[1] else 2)
        states.append(state)
    return states

def Zvalue(c):
    match c:
        case 0:
            return 1 if random.random() < 1-alpha else 0
        case 1:
            return 1 if random.random() < alpha else 0
        case 2:
            return 1 if random.random() < 0.5 else 0

# Simulate the for n neurons, starting (always) from state 2, and save the resulting states after T time-steps
startstate = 2
cstatelist = []
cstateslist = []
zlists = []
lambdalists = []
for i in range(n):
    state = startstate
    # Append all neuron states for this neuron to a list
    cstatelist = moveForward(state,T)
    # Add the neuron states to the list of all neurons
    cstateslist.append(cstatelist)
    Zlist = [Zvalue(c) for c in cstatelist]
    zlists.append(Zlist)
    lambdalist = [l0 if z == 0 else l1 for z in Zlist]
    lambdalists.append(lambdalist)
print("C states generated for each neuron: ", len(cstateslist), len(cstateslist[0]))
# Generate z values for each neuron based on the observed states in Clist
print("Z values generated for each neuron: ", len(zlists), len(zlists[0]))
# Add lambda for each neuron based on the z values
print("Lambda values generated for each neuron: ", len(lambdalists), len(lambdalists[0]))
# Generate Poisson samples based on the mean of the lambda values
meanlambdalist = np.mean(lambdalists[0])  # Use the first neuron's lambda list for mean calculation
Xlists = []
for i in range(n):
    Xlist = np.random.poisson(lam=meanlambdalist, size=T)
    Xlists.append(Xlist)
print("Poisson samples: ", len(Xlists), len(Xlists[0]))

# Plot X values for different neurons in different subplots
plt.figure(figsize=(12, 6))
for i in range(n):
    plt.subplot(n, 1, i+1)
    plt.plot(Xlists[i], label=f'X Neuron {i}')
    plt.scatter(range(len(Xlists[i])), Xlists[i], color='blue', label=f'X Neuron {i}', alpha=0.5)
    plt.title(f'Poisson Samples (X) for Neuron {i}')
plt.show()

# Plot mean of all neurons with mean curve and scatter plot
mean_Xlist = np.mean(Xlists, axis=0)
plt.figure(figsize=(12, 6))
plt.plot(mean_Xlist, label='Mean X across Neurons')
plt.scatter(range(len(mean_Xlist)), mean_Xlist, color='blue', label='MeanX across Neurons', alpha=0.5)
plt.title('Mean Poisson Samples (X) across Neurons')
plt.legend()
plt.show()
print(len(Xlists[0]), len(zlists[0]))

# Given X predict C using logistic regression

Xlists_flat = np.array(Xlists).flatten()
zlists_flat = np.array(zlists).flatten()
cstateslist_flat = np.array(cstateslist).flatten()
print(len(Xlists_flat), len(zlists_flat), len(cstateslist_flat))
# Prepare data for logistic regression
X = Xlists_flat.reshape(-1, 1)  # Reshape for sklearn
y = cstateslist_flat  # Target variable is the state C
# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Train logistic regression model
model = LogisticRegression(solver='lbfgs')
model.fit(X_train, y_train)
# Predict on the test set
y_pred = model.predict(X_test)
# Evaluate the model
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

